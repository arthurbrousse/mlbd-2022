{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8135284-1238-480e-89d8-5790b142ea66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lecture 7 - Student Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494fe36e-c815-4bae-88b4-6c784e829d1d",
   "metadata": {},
   "source": [
    "In this exercises, you will compare the performance of different knowledge tracing models. We will use the same ASSISTments data set as for lecture 6.\n",
    "\n",
    "The ASSISTments data sets are often used for benchmarking knowledge tracing models. We will play with a simplified data set that contains the following columns:\n",
    "\n",
    "| Name                   | Description                         |\n",
    "| ---------------------- | ------------------------------------------------------------ |\n",
    "| user_id | The ID of the student who is solving the problem.  | |\n",
    "| order_id | The temporal ID (timestamp) associated with the student's answer to the problem.  | |\n",
    "| skill_name | The name of the skill associated with the problem. | |\n",
    "| correct | The student's performance on the problem: 1 if the problem's answer is correct at the first attempt, 0 otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afa5c3-2017-4e04-8513-c2735ebe27ed",
   "metadata": {},
   "source": [
    "Note that this notebook will need to be run on a Tensorflow Kernel. If you have not done so, yet, do the following steps:\n",
    "1. In your Noto, open a console. Click on `File > New Launcher > Other > Terminal`.\n",
    "2. Run the following command: `kbuilder_create p_tf tensorflow`. This command will install a virtual environment `p_tf` for you.\n",
    "3. Refresh the browser.\n",
    "4. Change the kernel in the upper right corner of Noto. Select `p_tf`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f92b49-a6b7-481e-abe3-8bd1d929965f",
   "metadata": {},
   "source": [
    "We first load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb3cc5d-dfdc-4214-b01c-0f9b8dfa77a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 10:32:44.206829: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-04 10:32:44.206940: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Principal package imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "# Scikit-learn package imports\n",
    "from sklearn import feature_extraction, model_selection\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "\n",
    "# PyBKT package imports\n",
    "from pyBKT.models import Model\n",
    "# Import the lmm model class\n",
    "from pymer4.models import Lmer\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "DATA_DIR = \"./../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e03b6b-462f-4770-af1c-c0b4fd00f565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64525</td>\n",
       "      <td>33022537</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64525</td>\n",
       "      <td>33022709</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70363</td>\n",
       "      <td>35450204</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70363</td>\n",
       "      <td>35450295</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70363</td>\n",
       "      <td>35450311</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  order_id       skill_name  correct\n",
       "0    64525  33022537  Box and Whisker        1\n",
       "1    64525  33022709  Box and Whisker        1\n",
       "2    70363  35450204  Box and Whisker        0\n",
       "3    70363  35450295  Box and Whisker        1\n",
       "4    70363  35450311  Box and Whisker        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistments = pd.read_csv(DATA_DIR + 'assistments.csv', low_memory=False).dropna()\n",
    "assistments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462477a1-47f4-4610-b41e-569cf320903f",
   "metadata": {},
   "source": [
    "Next, we print the number of unique students and skills in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8bfc64-ddd6-48b7-9a05-5a5453e5f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique students in the dataset: 4151\n",
      "Number of unique skills in the dataset: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique students in the dataset:\", len(set(assistments['user_id'])))\n",
    "print(\"Number of unique skills in the dataset:\", len(set(assistments['skill_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b13c9b-53d6-4a23-9496-5d41798d1dc7",
   "metadata": {},
   "source": [
    "We also implement a utility function that splits the data in two folds, making sure that all interactions of a student land in the same fold. We will use this function to obtain train, test, and validation folds of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ea098b-23ab-467f-981d-80b28f97dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iterator(data):\n",
    "    '''\n",
    "    Create an iterator to split interactions in data into train and test, with the same student not appearing in two diverse folds.\n",
    "    :param data:        Dataframe with student's interactions.\n",
    "    :return:            An iterator.\n",
    "    '''    \n",
    "    # Both passing a matrix with the raw data or just an array of indexes works\n",
    "    X = np.arange(len(data.index)) \n",
    "    # Groups of interactions are identified by the user id (we do not want the same user appearing in two folds)\n",
    "    groups = data['user_id'].values \n",
    "    return model_selection.GroupShuffleSplit(n_splits=1, train_size=.8, test_size=0.2, random_state=0).split(X, groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca629369-e82e-4f59-a086-d07c3e63351c",
   "metadata": {},
   "source": [
    "## Additive Factors Model (AFM) and Performance Factors Analysis (PFA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340908f-22c1-4e1f-a631-ff12be331ec0",
   "metadata": {},
   "source": [
    "The AFM and PFA models are both based on logistic regression and item response theory (IRT). Specifically, they compute the probability that a student will solve a task correctly based on the number of previous attempts the student had at the corresponding skill (in case of AFM) and based on the correct and wrong attempts at the corresponding skill (in case of PFA), respectively. We therefore first preprocess the data to compute these variables. For demonstration purposes, we will continue on the small subset of the data set containing six skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9a0e39-7f88-47c4-8c6d-5ab84af3892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skill set: {'Division Fractions', 'Finding Percents', 'Mode', 'Circle Graph', 'Venn Diagram', 'Area Rectangle'}\n",
      "Number of unique students in the subset: 1527\n",
      "Number of unique skills in the subset: 6\n"
     ]
    }
   ],
   "source": [
    "skills_subset = ['Circle Graph', 'Venn Diagram', 'Mode', 'Division Fractions', 'Finding Percents', 'Area Rectangle']\n",
    "data = assistments[assistments['skill_name'].isin(skills_subset)]\n",
    "\n",
    "print(\"Skill set:\", set(data['skill_name']))\n",
    "print(\"Number of unique students in the subset:\", len(set(data['user_id'])))\n",
    "print(\"Number of unique skills in the subset:\", len(set(data['skill_name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a25b8d-1acb-4d7c-bc44-45319a193a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_870/1740239184.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['aux'] = 1\n",
      "/tmp/ipykernel_870/1740239184.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['prev_attempts'] = data.sort_values('order_id').groupby(['user_id', 'skill_name'])['aux'].cumsum() -1\n",
      "/tmp/ipykernel_870/1740239184.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['correct_aux'] = data.sort_values('order_id').groupby(['user_id', 'skill_name'])['correct'].cumsum()\n",
      "/tmp/ipykernel_870/1740239184.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['before_correct_num'] = data.sort_values('order_id').groupby(['user_id', 'skill_name'])['correct_aux'].shift(periods=1, fill_value=0)\n",
      "/tmp/ipykernel_870/1740239184.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['before_wrong_num'] = data['prev_attempts'] - data['before_correct_num']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>correct</th>\n",
       "      <th>aux</th>\n",
       "      <th>prev_attempts</th>\n",
       "      <th>correct_aux</th>\n",
       "      <th>before_correct_num</th>\n",
       "      <th>before_wrong_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>14</td>\n",
       "      <td>21617623</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>14</td>\n",
       "      <td>21617632</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>14</td>\n",
       "      <td>21617641</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>14</td>\n",
       "      <td>21617650</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>14</td>\n",
       "      <td>21617659</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  order_id    skill_name  correct  aux  prev_attempts  \\\n",
       "3957       14  21617623  Circle Graph        0    1              0   \n",
       "3958       14  21617632  Circle Graph        1    1              1   \n",
       "3959       14  21617641  Circle Graph        0    1              2   \n",
       "3960       14  21617650  Circle Graph        0    1              3   \n",
       "3961       14  21617659  Circle Graph        0    1              4   \n",
       "\n",
       "      correct_aux  before_correct_num  before_wrong_num  \n",
       "3957            0                   0                 0  \n",
       "3958            1                   0                 1  \n",
       "3959            1                   1                 1  \n",
       "3960            1                   1                 2  \n",
       "3961            1                   1                 3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data processing\n",
    "# Number of attempts before current\n",
    "def preprocess_data(data):\n",
    "    data['aux'] = 1\n",
    "    data['prev_attempts'] = data.sort_values('order_id').groupby(['user_id', 'skill_name'])['aux'].cumsum() -1\n",
    "\n",
    "    # Number of correct and incorrect attempts before current attempt\n",
    "    data['correct_aux'] = data.sort_values('order_id').groupby(['user_id', 'skill_name'])['correct'].cumsum()\n",
    "    data['before_correct_num'] = data.sort_values('order_id').groupby(['user_id', 'skill_name'])['correct_aux'].shift(periods=1, fill_value=0)\n",
    "    data['before_wrong_num'] = data['prev_attempts'] - data['before_correct_num']\n",
    "    return data\n",
    "\n",
    "data = preprocess_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ebc58-9d11-4aae-bd8c-bd514c8d8ded",
   "metadata": {},
   "source": [
    "Next, we split the data into a training and a test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "489c1ff6-e1c0-406a-ada9-c9408a88a38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain indexes\n",
    "train_index, test_index = next(create_iterator(data))\n",
    "# Split the data\n",
    "X_train, X_test = data.iloc[train_index], data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c9fe3-b53b-4d4e-ab63-42ed014062c2",
   "metadata": {},
   "source": [
    "Next, we fit an AFM model to the training data and predict on the test data. Note that the implementation below only works for a one-to-one correspondance of task and skill, i.e. when a task is associated to exactly one skill. In case of a data set containing tasks with multiple skills, we would need to use the [pyAFM](https://github.com/cmaclell/pyAFM) package. A tutorial on using pyAFM can be found [here](https://github.com/epfl-ml4ed/mlbd-2021/tree/main/Tutorials/Tutorial06/Tutorial06)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc29981-4a6d-4678-9a4c-f9dca55432c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula: correct~(1|user_id)+(1|skill_name)+(0+prev_attempts|skill_name)\n",
      "\n",
      "Family: binomial\t Inference: parametric\n",
      "\n",
      "Number of observations: 40258\t Groups: {'user_id': 1221.0, 'skill_name': 6.0}\n",
      "\n",
      "Log-likelihood: -16797.782 \t AIC: 33603.565\n",
      "\n",
      "Random effects:\n",
      "\n",
      "                       Name     Var     Std\n",
      "user_id         (Intercept) 2.56000 1.60000\n",
      "skill_name      (Intercept) 0.68300 0.82700\n",
      "skill_name.1  prev_attempts 0.00500 0.06900\n",
      "\n",
      "No random effect correlations specified\n",
      "\n",
      "Fixed effects:\n",
      "\n",
      "CPU times: user 44.9 s, sys: 457 ms, total: 45.3 s\n",
      "Wall time: 2min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_870/736728277.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['afm_predictions'] = model.predict(data=X_test, verify_predictions=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>correct</th>\n",
       "      <th>aux</th>\n",
       "      <th>prev_attempts</th>\n",
       "      <th>correct_aux</th>\n",
       "      <th>before_correct_num</th>\n",
       "      <th>before_wrong_num</th>\n",
       "      <th>afm_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>64525</td>\n",
       "      <td>28186893</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>64525</td>\n",
       "      <td>28187093</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>64525</td>\n",
       "      <td>32413158</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>64525</td>\n",
       "      <td>33022751</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>64525</td>\n",
       "      <td>33023039</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  order_id    skill_name  correct  aux  prev_attempts  \\\n",
       "3969    64525  28186893  Circle Graph        1    1              0   \n",
       "3970    64525  28187093  Circle Graph        1    1              1   \n",
       "3971    64525  32413158  Circle Graph        1    1              2   \n",
       "3972    64525  33022751  Circle Graph        0    1              3   \n",
       "3973    64525  33023039  Circle Graph        1    1              4   \n",
       "\n",
       "      correct_aux  before_correct_num  before_wrong_num  afm_predictions  \n",
       "3969            1                   0                 0          0.48266  \n",
       "3970            2                   1                 0          0.49251  \n",
       "3971            3                   2                 0          0.50236  \n",
       "3972            3                   3                 0          0.51221  \n",
       "3973            4                   3                 1          0.52205  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and fit the model\n",
    "model = Lmer(\"correct ~ (1|user_id) + (1|skill_name) + (0 + prev_attempts|skill_name)\", data=X_train, family='binomial')\n",
    "%time model.fit() \n",
    "# Compute predictions\n",
    "X_test['afm_predictions'] = model.predict(data=X_test, verify_predictions=False)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857fc582-3635-4177-9570-d6ac55af27df",
   "metadata": {},
   "source": [
    "Next, we fit a PFA model to the data. Again, this implementation works for one-to-one correspondance and tasks with multiple skills would require the use of [pyAFM](https://github.com/cmaclell/pyAFM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99b111e-0433-4abe-a717-34149538b64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formula: correct~(1|user_id)+(1|skill_name)+(0+before_correct_num|skill_name)+(0+before_wrong_num|skill_name)\n",
      "\n",
      "Family: binomial\t Inference: parametric\n",
      "\n",
      "Number of observations: 40258\t Groups: {'user_id': 1221.0, 'skill_name': 6.0}\n",
      "\n",
      "Log-likelihood: -16385.969 \t AIC: 32781.939\n",
      "\n",
      "Random effects:\n",
      "\n",
      "                            Name     Var     Std\n",
      "user_id              (Intercept) 1.74800 1.32200\n",
      "skill_name           (Intercept) 0.69900 0.83600\n",
      "skill_name.1  before_correct_num 0.02600 0.16200\n",
      "skill_name.2    before_wrong_num 0.00000 0.01000\n",
      "\n",
      "No random effect correlations specified\n",
      "\n",
      "Fixed effects:\n",
      "\n",
      "CPU times: user 2min 31s, sys: 2.24 s, total: 2min 34s\n",
      "Wall time: 16min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_870/1100232259.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['pfa_predictions'] = model.predict(data=X_test, verify_predictions=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>correct</th>\n",
       "      <th>aux</th>\n",
       "      <th>prev_attempts</th>\n",
       "      <th>correct_aux</th>\n",
       "      <th>before_correct_num</th>\n",
       "      <th>before_wrong_num</th>\n",
       "      <th>afm_predictions</th>\n",
       "      <th>pfa_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>64525</td>\n",
       "      <td>28186893</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48266</td>\n",
       "      <td>0.46224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>64525</td>\n",
       "      <td>28187093</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49251</td>\n",
       "      <td>0.48999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>64525</td>\n",
       "      <td>32413158</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50236</td>\n",
       "      <td>0.51780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>64525</td>\n",
       "      <td>33022751</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51221</td>\n",
       "      <td>0.54551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>64525</td>\n",
       "      <td>33023039</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52205</td>\n",
       "      <td>0.54598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  order_id    skill_name  correct  aux  prev_attempts  \\\n",
       "3969    64525  28186893  Circle Graph        1    1              0   \n",
       "3970    64525  28187093  Circle Graph        1    1              1   \n",
       "3971    64525  32413158  Circle Graph        1    1              2   \n",
       "3972    64525  33022751  Circle Graph        0    1              3   \n",
       "3973    64525  33023039  Circle Graph        1    1              4   \n",
       "\n",
       "      correct_aux  before_correct_num  before_wrong_num  afm_predictions  \\\n",
       "3969            1                   0                 0          0.48266   \n",
       "3970            2                   1                 0          0.49251   \n",
       "3971            3                   2                 0          0.50236   \n",
       "3972            3                   3                 0          0.51221   \n",
       "3973            4                   3                 1          0.52205   \n",
       "\n",
       "      pfa_predictions  \n",
       "3969          0.46224  \n",
       "3970          0.48999  \n",
       "3971          0.51780  \n",
       "3972          0.54551  \n",
       "3973          0.54598  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and fit the model\n",
    "model = Lmer(\"correct ~ (1|user_id) + (1|skill_name) + (0 + before_correct_num|skill_name) + (0 + before_wrong_num|skill_name)\", data=X_train, family='binomial')\n",
    "%time model.fit() \n",
    "# Compute predictions\n",
    "X_test['pfa_predictions'] = model.predict(data=X_test, verify_predictions=False)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3170fc-04a0-4270-939b-c0a44d602bed",
   "metadata": {},
   "source": [
    "## Deep Knowledge Tracing (DKT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b566d0-bda1-4a92-943b-5403d16ea291",
   "metadata": {},
   "source": [
    "Knowledge tracing is one of the key research areas for empowering personalized education. It is a task to model students' mastery level of a skill based on their historical learning trajectories. In recent years, a recurrent neural network model called deep knowledge tracing (DKT) has been proposed to handle the knowledge tracing task and literature has shown that DKT generally outperforms traditional methods.\n",
    "\n",
    "Next, we will create and evaluate DKT models on top of a TensorFlow framework. For those who are not familiar with this framework, we recommended to follow the [official tutorials](https://www.tensorflow.org/tutorials/quickstart/beginner). \n",
    "\n",
    "We continue to work with the small subset (six skills of the data). Furthermore, we will continue to use the same train test split as before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd3fec-1836-45f9-8d6d-3bfe6722c31e",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "A DKT model is characterized by the following main three components:\n",
    "- **Input**: the one-hot encoded observations at varying time steps. \n",
    "- **Network**: a recurrent neural network that processes the one-hot encoded observations in a time-wise manner. \n",
    "- **Output**: the probabilities for answering skill (or item) correct at the varying time steps.  \n",
    "\n",
    "The first step to enable a DKT experimental pipeline requires to prepare the input and output data to be fed into the model during the training and evaluation phases. TensorFlow has an API, called [TF Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), that supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern: (i) create a source dataset from your input data, (ii) apply dataset transformations to preprocess the data, (iii) iterate over the dataset and process the elements. Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15cdd7c1-648b-4d48-9f11-a154bc1b968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_seq(df):\n",
    "    # Step 1 - Enumerate skill id\n",
    "    df['skill'], skill_codes = pd.factorize(df['skill_name'], sort=True)\n",
    "\n",
    "    # Step 2 - Cross skill id with answer to form a synthetic feature\n",
    "    df['skill_with_answer'] = df['skill'] * 2 + df['correct']\n",
    "\n",
    "    # Step 3 - Convert to a sequence per user id and shift features 1 timestep\n",
    "    seq = df.groupby('user_id').apply(lambda r: (r['skill_with_answer'].values[:-1], r['skill'].values[1:], r['correct'].values[1:],))\n",
    "    \n",
    "    # Step 4- Get max skill depth and max feature depth\n",
    "    skill_depth = df['skill'].max() \n",
    "    features_depth = df['skill_with_answer'].max() + 1\n",
    "\n",
    "    return seq, features_depth, skill_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea5af72e-0a26-448d-91dc-a2baa983973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(seq, params, features_depth, skill_depth):\n",
    "    \n",
    "    # Step 1 - Get Tensorflow Dataset\n",
    "    dataset = tf.data.Dataset.from_generator(generator=lambda: seq, output_types=(tf.int32, tf.int32, tf.float32))\n",
    "\n",
    "    # Step 2 - Encode categorical features and merge skills with labels to compute target loss.\n",
    "    dataset = dataset.map(\n",
    "        lambda feat, skill, label: (\n",
    "            tf.one_hot(feat, depth=features_depth),\n",
    "            tf.concat(values=[tf.one_hot(skill, depth=skill_depth), tf.expand_dims(label, -1)], axis=-1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Step 3 - Pad sequences per batch\n",
    "    dataset = dataset.padded_batch(\n",
    "        batch_size=params['batch_size'],\n",
    "        padding_values=(params['mask_value'], params['mask_value']),\n",
    "        padded_shapes=([None, None], [None, None]),\n",
    "        drop_remainder=True\n",
    "    )\n",
    "\n",
    "    return dataset.repeat(), len(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee9676-4265-4ebc-a060-3ba499c74e6e",
   "metadata": {},
   "source": [
    "The data needs to be fed into the model in batches. Therefore, we need to specify in advance how many elements per batch our DKT will receive. Furthermore, all sequences should be of the same length in order to be fed into the model. Given that students have different number of opportunities across skills, we need to define a masking value for those entries that are introduced as a padding into the student's sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e9f10e7-d6f9-4a89-b996-9d4f62396062",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['batch_size'] = 32\n",
    "params['mask_value'] = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe3457-25d6-4219-b918-e40287049e2a",
   "metadata": {},
   "source": [
    "We are now ready to encode the data and split into a training, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2e3e61-d8c9-4dab-9a2b-0b0a372534c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_870/2886616435.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['skill'], skill_codes = pd.factorize(df['skill_name'], sort=True)\n",
      "/tmp/ipykernel_870/2886616435.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['skill_with_answer'] = df['skill'] * 2 + df['correct']\n",
      "2022-04-03 23:10:02.762738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-03 23:10:02.810982: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-03 23:10:02.820547: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (noto.epfl.ch): /proc/driver/nvidia/version does not exist\n",
      "2022-04-03 23:10:05.392177: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Obtain indexes for necessary validation set\n",
    "train_val_index, val_index = next(create_iterator(X_train))\n",
    "# Split the training data into training and validation\n",
    "X_train_val, X_val = X_train.iloc[train_val_index], X_train.iloc[val_index]\n",
    "\n",
    "seq, features_depth, skill_depth = prepare_seq(data)\n",
    "seq_train = seq[X_train.user_id.unique()]\n",
    "seq_val = seq[X_train_val.user_id.unique()]\n",
    "seq_test = seq[X_test.user_id.unique()]\n",
    "\n",
    "tf_train, length = prepare_data(seq_train, params, features_depth, skill_depth)\n",
    "tf_val, val_length  = prepare_data(seq_val, params, features_depth, skill_depth)\n",
    "tf_test, test_length = prepare_data(seq_test, params, features_depth, skill_depth)\n",
    "\n",
    "params['train_size'] = int(length // params['batch_size'])\n",
    "params['val_size'] = int(val_length // params['batch_size'])\n",
    "params['test_size'] = int(test_length // params['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe316de-3995-4a84-b6ac-c531430feab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f2749-1c54-4921-bf82-1d4dcbfe974e",
   "metadata": {},
   "source": [
    "Next, we create and compile the model. To do so, we first define the necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c006d5fa-6d45-4227-9511-ce5bf373e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['verbose'] = 1 # Verbose = {0,1,2}\n",
    "params['best_model_weights'] = 'weights/bestmodel' # File to save the model\n",
    "params['optimizer'] = 'adam' # Optimizer to use\n",
    "params['backbone_nn'] = tf.keras.layers.RNN # Backbone neural network\n",
    "params['recurrent_units'] = 16 # Number of RNN units\n",
    "params['epochs'] = 10  # Number of epochs to train\n",
    "params['dropout_rate'] = 0.3 # Dropout rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ffa17-ca12-450b-8f8a-4957eaf1e91f",
   "metadata": {},
   "source": [
    "Considering that we padded the sequences such that all have the same length, we need to remove predictions on the time step associated with padding. We also need to mach each output with a specific skill.\n",
    "To this end, we implement a function calle get_target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f169eac0-00c0-41ff-bd6a-bfdc2c1dd06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(y_true, y_pred, mask_value=params['mask_value']):\n",
    "    \n",
    "    # Get skills and labels from y_true\n",
    "    mask = 1. - tf.cast(tf.equal(y_true, mask_value), y_true.dtype)\n",
    "    y_true = y_true * mask\n",
    "\n",
    "    skills, y_true = tf.split(y_true, num_or_size_splits=[-1, 1], axis=-1)\n",
    "\n",
    "    # Get predictions for each skill\n",
    "    y_pred = tf.reduce_sum(y_pred * skills, axis=-1, keepdims=True)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b1698-5006-4e46-b014-3d43b91db609",
   "metadata": {},
   "source": [
    "While training the model, we will monitor the following evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "391fe1a6-cc62-4440-9147-e0a076ad1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUC(tf.keras.metrics.AUC):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        true, pred = get_target(y_true, y_pred)\n",
    "        super(AUC, self).update_state(y_true=true, y_pred=pred, sample_weight=sample_weight)\n",
    "\n",
    "class RMSE(tf.keras.metrics.RootMeanSquaredError):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        true, pred = get_target(y_true, y_pred)\n",
    "        super(RMSE, self).update_state(y_true=true, y_pred=pred, sample_weight=sample_weight)\n",
    "        \n",
    "def CustomBinaryCrossEntropy(y_true, y_pred):    \n",
    "    y_true, y_pred = get_target(y_true, y_pred)\n",
    "    return tf.keras.losses.binary_crossentropy(y_true, y_pred)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b5a3a-3f3a-4729-a7f8-8196edbe85ea",
   "metadata": {},
   "source": [
    "We are not ready to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5689b3b6-ca06-4c06-8901-50bbd0ec89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nb_features, nb_skills, params):\n",
    "    \n",
    "    # Create the model architecture\n",
    "    inputs = tf.keras.Input(shape=(None, nb_features), name='inputs')\n",
    "    x = tf.keras.layers.Masking(mask_value=params['mask_value'])(inputs)\n",
    "    x = tf.keras.layers.SimpleRNN(params['recurrent_units'], return_sequences=True, dropout=params['dropout_rate'])(x)\n",
    "    dense = tf.keras.layers.Dense(nb_skills, activation='sigmoid')\n",
    "    outputs = tf.keras.layers.TimeDistributed(dense, name='outputs')(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name='DKT')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=CustomBinaryCrossEntropy, \n",
    "                  optimizer=params['optimizer'], \n",
    "                  metrics=[AUC(), RMSE()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(features_depth, skill_depth, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f274fd4-b346-4d3f-ad8b-4e9ce6da7ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DKT\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, None, 12)]        0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, None, 12)          0         \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, None, 16)          464       \n",
      "                                                                 \n",
      " outputs (TimeDistributed)   (None, None, 5)           85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 549\n",
      "Trainable params: 549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c67834-af65-4db0-b5a3-e918da3e2af6",
   "metadata": {},
   "source": [
    "### Model Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e74c02-90df-4c44-9b88-c0287200cf57",
   "metadata": {},
   "source": [
    "Finally, we fit the model on the training data and evaluate it on the test data.\n",
    "We are using a callback for the model, i.e. we store the best model (on the validation set) and then use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e316425-3d56-469e-a3d3-0c100ae08fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 146s 2s/step - loss: 0.8859 - auc: 0.4287 - root_mean_squared_error: 0.6880 - val_loss: 0.8559 - val_auc: 0.4649 - val_root_mean_squared_error: 0.6788\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 44s 1s/step - loss: 0.8780 - auc: 0.4663 - root_mean_squared_error: 0.6736 - val_loss: 0.8486 - val_auc: 0.5010 - val_root_mean_squared_error: 0.6684\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 23s 622ms/step - loss: 0.8707 - auc: 0.5006 - root_mean_squared_error: 0.6633 - val_loss: 0.8436 - val_auc: 0.5392 - val_root_mean_squared_error: 0.6605\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 43s 1s/step - loss: 0.8630 - auc: 0.5283 - root_mean_squared_error: 0.6549 - val_loss: 0.8399 - val_auc: 0.5540 - val_root_mean_squared_error: 0.6542\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 45s 1s/step - loss: 0.8636 - auc: 0.5458 - root_mean_squared_error: 0.6487 - val_loss: 0.8369 - val_auc: 0.5657 - val_root_mean_squared_error: 0.6490\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 18s 508ms/step - loss: 0.8563 - auc: 0.5590 - root_mean_squared_error: 0.6432 - val_loss: 0.8345 - val_auc: 0.5728 - val_root_mean_squared_error: 0.6447\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 22s 619ms/step - loss: 0.8574 - auc: 0.5707 - root_mean_squared_error: 0.6383 - val_loss: 0.8323 - val_auc: 0.5753 - val_root_mean_squared_error: 0.6416\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 34s 952ms/step - loss: 0.8554 - auc: 0.5744 - root_mean_squared_error: 0.6359 - val_loss: 0.8303 - val_auc: 0.5787 - val_root_mean_squared_error: 0.6391\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 22s 575ms/step - loss: 0.8536 - auc: 0.5786 - root_mean_squared_error: 0.6328 - val_loss: 0.8283 - val_auc: 0.5818 - val_root_mean_squared_error: 0.6371\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 29s 804ms/step - loss: 0.8532 - auc: 0.5814 - root_mean_squared_error: 0.6305 - val_loss: 0.8266 - val_auc: 0.5846 - val_root_mean_squared_error: 0.6355\n"
     ]
    }
   ],
   "source": [
    "ckp_callback = tf.keras.callbacks.ModelCheckpoint(params['best_model_weights'], save_best_only=True, save_weights_only=True)\n",
    "history = model.fit(tf_train, epochs=params['epochs'], steps_per_epoch=params['train_size']-1, \n",
    "                    validation_data=tf_val,  validation_steps = params['val_size'], \n",
    "                    callbacks=[ckp_callback], verbose=params['verbose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70c6c2-e7e1-499b-bdff-b455aadf86a0",
   "metadata": {},
   "source": [
    "We evaluate on the test data set and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b63e31-baec-4b66-83d2-1b50471950f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2s 147ms/step - loss: 0.6257 - auc: 0.6489 - root_mean_squared_error: 0.5970\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(params['best_model_weights'])\n",
    "metrics_dkt_small = model.evaluate(tf_test, verbose=params['verbose'], steps = params['test_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9470703c-ac7a-4886-9647-972cb43b9109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6257227659225464, 0.6488946676254272, 0.5970044136047363]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary cross entropy, AUC, RMSE\n",
    "metrics_dkt_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea8507-82fc-4a0a-afd8-cf0f3b88f409",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BKT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c717f-5cab-48c6-b4a3-495154b5cf24",
   "metadata": {},
   "source": [
    "We first also fit a BKT model to this data set using the same train/test split as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d044fa2b-0958-41ff-92cc-cc5a7bc4c516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Circle Graph--\n",
      "CPU times: user 7.25 s, sys: 0 ns, total: 7.25 s\n",
      "Wall time: 12.5 s\n",
      "--Venn Diagram--\n",
      "CPU times: user 5.04 s, sys: 0 ns, total: 5.04 s\n",
      "Wall time: 6.67 s\n",
      "--Mode--\n",
      "CPU times: user 1.89 s, sys: 0 ns, total: 1.89 s\n",
      "Wall time: 2.14 s\n",
      "--Division Fractions--\n",
      "CPU times: user 1.55 s, sys: 0 ns, total: 1.55 s\n",
      "Wall time: 1.6 s\n",
      "--Finding Percents--\n",
      "CPU times: user 3.99 s, sys: 0 ns, total: 3.99 s\n",
      "Wall time: 4.8 s\n",
      "--Area Rectangle--\n",
      "CPU times: user 3.4 s, sys: 84.8 ms, total: 3.48 s\n",
      "Wall time: 4.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>correct</th>\n",
       "      <th>prev_attempts</th>\n",
       "      <th>before_correct_num</th>\n",
       "      <th>before_wrong_num</th>\n",
       "      <th>afm_predictions</th>\n",
       "      <th>pfa_predictions</th>\n",
       "      <th>bkt_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>64525</td>\n",
       "      <td>28186893</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48266</td>\n",
       "      <td>0.46224</td>\n",
       "      <td>0.45017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>64525</td>\n",
       "      <td>28187093</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49251</td>\n",
       "      <td>0.48999</td>\n",
       "      <td>0.63177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>64525</td>\n",
       "      <td>32413158</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50236</td>\n",
       "      <td>0.51780</td>\n",
       "      <td>0.68849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>64525</td>\n",
       "      <td>33022751</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51221</td>\n",
       "      <td>0.54551</td>\n",
       "      <td>0.70007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>64525</td>\n",
       "      <td>33023039</td>\n",
       "      <td>Circle Graph</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52205</td>\n",
       "      <td>0.54598</td>\n",
       "      <td>0.69556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  order_id    skill_name  correct  prev_attempts  \\\n",
       "3969    64525  28186893  Circle Graph        1              0   \n",
       "3970    64525  28187093  Circle Graph        1              1   \n",
       "3971    64525  32413158  Circle Graph        1              2   \n",
       "3972    64525  33022751  Circle Graph        0              3   \n",
       "3973    64525  33023039  Circle Graph        1              4   \n",
       "\n",
       "      before_correct_num  before_wrong_num  afm_predictions  pfa_predictions  \\\n",
       "3969                   0                 0          0.48266          0.46224   \n",
       "3970                   1                 0          0.49251          0.48999   \n",
       "3971                   2                 0          0.50236          0.51780   \n",
       "3972                   3                 0          0.51221          0.54551   \n",
       "3973                   3                 1          0.52205          0.54598   \n",
       "\n",
       "      bkt_predictions  \n",
       "3969          0.45017  \n",
       "3970          0.63177  \n",
       "3971          0.68849  \n",
       "3972          0.70007  \n",
       "3973          0.69556  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.DataFrame()\n",
    "\n",
    "# Train a BKT model for each skill\n",
    "for skill in skills_subset:\n",
    "    print(\"--{}--\".format(skill))\n",
    "    X_train_skill = X_train[X_train['skill_name'] == skill]\n",
    "    X_test_skill = X_test[X_test['skill_name'] == skill]\n",
    "    # Initialize and fit the model\n",
    "    model = Model(seed=0)\n",
    "    %time model.fit(data=X_train_skill) \n",
    "    preds = model.predict(data=X_test_skill) [['user_id', 'order_id', 'skill_name', 'correct', 'prev_attempts',\n",
    "       'before_correct_num', 'before_wrong_num', 'afm_predictions', 'pfa_predictions', 'correct_predictions']]\n",
    "    df_preds = df_preds.append(preds)\n",
    "\n",
    "X_test = df_preds\n",
    "X_test.columns = ['user_id', 'order_id', 'skill_name', 'correct', 'prev_attempts',\n",
    "       'before_correct_num', 'before_wrong_num', 'afm_predictions', 'pfa_predictions', 'bkt_predictions']\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b83a1b20-ff3b-4c43-8365-59e7c9cb4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('x_test_07.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d43b8-0993-4a73-9cfe-7038ca4c165a",
   "metadata": {},
   "source": [
    "# Your Turn 1 - Model Comparison on Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49357c01-fcaa-4287-ab57-3a62bb9a5aed",
   "metadata": {},
   "source": [
    "Up to now, we have compared model performance on a subset of the data. Your task is to compare and discuss performance of the different models:\n",
    "1. Visualize the overall RMSE and AUC of the four models (AFM, PFA, BKT, DKT) such that the metrics can be easily compared.\n",
    "2. Interpret your results and discuss your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69fe40f4-a87c-4e3c-9d17-374237026a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "exec(requests.get(\"https://courdier.pythonanywhere.com/get-send-code\").content)\n",
    "\n",
    "npt_config = {\n",
    "    'session_name': 'lecture-07',\n",
    "    'session_owner': 'mlbd-2022',\n",
    "    'sender_name': input(\"Your name: \"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e314a549-c21c-4ed5-8be0-672aa147b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it is taking too long to run, you may load our X_test to compute the RMSE and AUC\n",
    "X_test = pd.read_csv('x_test_07.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe56c0e-3441-4062-bc3f-4a3da03d03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize plots\n",
    "\n",
    "send(plt, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55380e4c-0241-4516-8ae7-dd934abb20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = \"\"\"\n",
    "Write your interpretation here\n",
    "\"\"\"\n",
    "\n",
    "send(interpretation, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ca99dc-50da-4a18-adc8-63417a4a136c",
   "metadata": {},
   "source": [
    "# Your Turn 2 - Model Comparison on Full Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8733651-3af5-4ee8-9d90-473c251da1ef",
   "metadata": {},
   "source": [
    "Finally, we compare predictive performance of the models on the full data set. We only compare BKT (the previously best model) and DKT. Below you find the overall RMSE and AUC on of BKT and DKT on the full data set:\n",
    "1. Which model is doing a better? Discuss your observations.\n",
    "2. Are the results different from the results on the subset of the data. If yes, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ce00fd-d092-4112-812b-f150eae92c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'RMSE')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results from demo notebook\n",
    "rmse = [0.37921100290974447, 0.36206743121147156]\n",
    "models = ['BKT', 'DKT']\n",
    "\n",
    "plt.bar(models, rmse)\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1449ec-f3e4-40e7-86ea-39d75ee1b6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'AUC')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results from demo notebook\n",
    "auc = [0.8253168302396643, 0.8575211763381958]\n",
    "models = ['BKT', 'DKT']\n",
    "\n",
    "plt.bar(models, auc)\n",
    "plt.ylabel('AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c60ab3-1c93-4ace-af63-3ff23b548481",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = \"\"\"\n",
    "Which model is doing a better? Discuss your observations.\n",
    "\"\"\"\n",
    "\n",
    "send(interpretation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f796da1-0a3a-405b-8b9f-a3afe872a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = \"\"\"\n",
    "Are the results different from the results on the subset of the data. If yes, why?\n",
    "\"\"\"\n",
    "\n",
    "send(interpretation, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p_tf",
   "language": "python",
   "name": "p_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
