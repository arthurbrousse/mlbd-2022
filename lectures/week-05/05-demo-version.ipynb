{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891ad0db-af6a-4311-8f98-865c5197682a",
   "metadata": {},
   "source": [
    "# Lecture 5 - Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d46922-ee6e-4a8c-bddf-8a0b893a9ffe",
   "metadata": {},
   "source": [
    "We first load and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad19540-3541-4151-9bf4-f1987ed2048e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, auc\n",
    "from sklearn.utils import resample\n",
    "\n",
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd61b5d-f273-4616-aa44-c0874a579baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the aggregated student data frame.\n",
    "# This data is from an EPFL Linear Algebra flipped classroom. df_lq is aggregated features for the last week of student performance.\n",
    "# ts represents the students' time series features.\n",
    "\n",
    "df_lq = pd.read_csv('{}/aggregated_extended_fc.csv'.format(DATA_DIR))\n",
    "ts = pd.read_csv('{}/time_series_extended_fc.csv'.format(DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72168118-0033-47c4-ae99-2ba3b6891267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_inactive_students(df, ts):\n",
    "    \"\"\"\n",
    "    Filter the students (removing the ones that are inactive) to proceed with analysis on students who have participated during the entire class.\n",
    "    Inputs: df, ts\n",
    "    Outputs: filtered df, ts\n",
    "    \"\"\"\n",
    "    # Fill all NaNs with strings to make them easier to process\n",
    "    df = df.fillna('NaN')\n",
    "    \n",
    "    # Find all users weeks with 0 clicks on weekends and 0 clicks on weekdays during the first few weeks of the semester\n",
    "    df_first = ts[ts.week < 5]\n",
    "    rows = np.where(np.logical_and(df_first.ch_total_clicks_weekend==0, df_first.ch_total_clicks_weekday==0).to_numpy())[0]\n",
    "    df_zero = df_first.iloc[rows, :]\n",
    "    dropusers = np.unique(df_zero.user)\n",
    "\n",
    "    # Drop users with no activity\n",
    "    ts = ts[~ts.user.isin(dropusers)]\n",
    "    df = df[~df.user.isin(dropusers)]\n",
    "    return df, ts\n",
    "\n",
    "df_lq, ts = remove_inactive_students(df_lq, ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b2539-bcfc-40df-83d1-9eff25270fec",
   "metadata": {},
   "source": [
    "The `compute_scores` function computes the performance of classifiers with accuracy + AUC. We will use this evaluation function for all our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2b78680-efbe-4a07-9213-7c8522698a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(clf, X_train, y_train, X_test, y_test, roundnum=3, report=False):\n",
    "    \"\"\"\n",
    "    Train clf (binary classification) model on X_train and y_train, predict on X_test. Evaluate predictions against ground truth y_test.\n",
    "    Inputs: clf, training set (X_train, y_train), test set (X_test, y_test)\n",
    "    Inputs (optional): roundnum (number of digits for rounding metrics), report (print scores)\n",
    "    Outputs: accuracy, AUC\n",
    "    \"\"\"\n",
    "    # Fit the clf predictor (passed in as an argument)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate roc AUC score\n",
    "    AUC = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    # Print classification results\n",
    "    if report:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return round(accuracy, roundnum), round(AUC, roundnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ca4d9-f07f-4246-bb78-ad1fb3835d51",
   "metadata": {},
   "source": [
    "We compute the pass/fail label of the students in the dataframe to use for the experiments. We will use the aggregated dataframe (df_lq) for all our experiments. If students have a grade higher than or equal to 4, they have passed the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "593c81c9-5d4d-4ddc-8b9b-6b3def76169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lq['passed'] = (df_lq.grade >= 4).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ae905-fdf7-4118-8744-6fd76f5d1f32",
   "metadata": {},
   "source": [
    "## Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd443ce2-e939-40fe-8870-1c4f87108265",
   "metadata": {},
   "source": [
    "In a next step, we are interested in evaluating the generalizability of our models. We will use a random forest model for all our evaluations. For our evaluations, we will investigate behavioral features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7de2d363-8d4f-4719-ae67-dfff6dd95f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ch_num_sessions', 'ch_time_in_prob_sum', 'ch_time_in_video_sum', 'ch_ratio_clicks_weekend_day', 'ch_total_clicks_weekend', 'ch_total_clicks_weekday', 'ch_time_sessions_mean', 'ch_time_sessions_std', 'bo_delay_lecture', 'bo_reg_peak_dayhour', 'bo_reg_periodicity_m1', 'ma_competency_strength', 'ma_competency_anti', 'ma_content_anti', 'ma_student_shape', 'ma_student_speed', 'mu_speed_playback_mean', 'mu_frequency_action_relative_video_pause', 'wa_num_subs', 'wa_num_subs_correct', 'wa_num_subs_avg', 'wa_num_subs_perc_correct', 'la_pause_dur_mean', 'la_seek_len_std', 'la_pause_dur_std', 'la_time_speeding_up_mean', 'la_time_speeding_up_std', 'la_weekly_prop_watched_mean', 'la_weekly_prop_interrupted_mean', 'la_weekly_prop_interrupted_std', 'la_weekly_prop_replayed_mean', 'la_weekly_prop_replayed_std', 'la_frequency_action_video_play']\n"
     ]
    }
   ],
   "source": [
    "# Filter out demographic features\n",
    "features = [x for x in df_lq.columns if x not in ['user', 'week', 'grade', 'gender', 'category', 'year', 'passed']]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "561753df-2e54-45fe-baac-65c867a00019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep behavioral features in X.\n",
    "X = df_lq[features]\n",
    "\n",
    "# Our binary indicator variable is based on our evaluation criteria: pass/fail.\n",
    "y = df_lq['passed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc04c79-7cdc-4f81-b361-ef309004c8b3",
   "metadata": {},
   "source": [
    "### Train-Test Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72257d09",
   "metadata": {},
   "source": [
    "We split the data in a train-test split (stratified by the outcome variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24643627-f9ed-4d43-b6f7-b454e4f28629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train-test split is 80:20 (as shown by the 0.2 test_size argument). \n",
    "# We choose a random_state to replicate the results in the same split every time we run this notebook.\n",
    "# The stratify argument ensures a proportionate number of passes/fails are in the training set and the test set.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4b14647-55de-41e7-850e-b708564c7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's initialize a RandomForestClassifier to make our model predictions.\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a1b3e51-6eae-4e92-b45c-a64903a03aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train-test setting: 0.723\n",
      "AUC for train-test setting: 0.723\n"
     ]
    }
   ],
   "source": [
    "# We can use our compute_scores function to evaluate the results of our train-test split classifier.\n",
    "\n",
    "accuracy, AUC = compute_scores(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(f'Accuracy for train-test setting: {accuracy}')\n",
    "print(f'AUC for train-test setting: {AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a332370-626f-4c99-a8ef-2d6d0973ed9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41970544-d7c1-4008-b5e7-02de9a625683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new Random Forest predictor for our cross-validation comparison.\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43f55e37-caab-4d85-80d8-b93868f04fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy with cross-validation: 0.679\n",
      "Mean AUC with cross-validation: 0.680\n"
     ]
    }
   ],
   "source": [
    "# With the cross_validate function, the SciKit Learn library automatically uses stratification across folds with the \"cv\" argument. \n",
    "# In the background, it's using the StratifiedKFold function with 10 folds.\n",
    "# We pass in our desired metrics (\"accuracy\", \"roc_auc\") for evaluation in the \"scoring\" argument.\n",
    "\n",
    "scores = cross_validate(clf, X, y, cv=10, scoring=['accuracy', 'roc_auc'])\n",
    "\n",
    "print(f'Mean accuracy with cross-validation: {scores[\"test_accuracy\"].mean():.3f}')\n",
    "print(f'Mean AUC with cross-validation: {scores[\"test_roc_auc\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b4446-9e6c-49a5-be73-c940c16df560",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff3403e-c341-4792-a952-7bb9b14b7797",
   "metadata": {},
   "source": [
    "Next, we use bootstrapping to evaluate our model. For this evaluation method, we can only compute the accuracy, but not the AUC.\n",
    "\n",
    "The ROC curve is defined as the False Positive Rate, FPR = FP / (TN + FP), vs the True Positive Rate, TPR = TP / (TP + FN). However, when we consider a set of data points all with the same label, one of those two rates is undefined. \n",
    "\n",
    "In the setting of leave-one-out bootstrapping, we can confirm that this happens when we consider the predictions for the data point $i$ of all predictors $b \\in C^{-i}$. If the point $i$ had label 1, then all the predictions for it would be either TP or FN, with FPR being undefined, while if it had label 0 all the predictions would be either TN or FP, with FPR undefined. Therefore, we will only consider accuracy as metric for bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac6b55-742a-4fa2-9772-26573ce806e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It is important to sample with:\n",
    "# (1) the same size as the initial df (df_size) \n",
    "# (2) with replacement (replace=True)\n",
    "# for the bootstrap samples to be representative.\n",
    "df_size = len(df_lq)\n",
    "B = 100\n",
    "\n",
    "# Generate B bootstrap samples of the dataset with replacement.\n",
    "samples = [resample(X, y, replace=True, n_samples=df_size) for b in range(B)]\n",
    "\n",
    "# Train a random forest classifier for each bootstrap set\n",
    "clfs = [RandomForestClassifier(random_state=42).fit(X_b, y_b) for X_b, y_b in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8892563b-7589-4edb-8317-288402e46285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predictions for each bootstrap sample (b in range(B)).\n",
    "# Compare predictions against the ground truth (y.loc[[user]]). \n",
    "# Take the mean of predictions for each student (over on the number of times they were predicted).\n",
    "# Takes ~2 mins\n",
    "accuracies = [np.mean([clfs[b].predict(X.loc[[user]]) == y.loc[[user]] for b in range(B) if user not in samples[b][0].index])\n",
    "              for user in df_lq.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bec11506-d74f-40ef-a0cc-33a8ecb7349c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6776790837850795"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the mean of predictions across all students.\n",
    "bootstrap_err = np.mean(accuracies)\n",
    "bootstrap_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf66237b-b566-4ded-b565-3ac227105a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607264957264958"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the training error for each bootstrapped model, then average across bootstraps.\n",
    "training_err_bootstrap = [clfs[b].score(samples[b][0], samples[b][1]) for b in range(B)]\n",
    "training_err = np.mean(training_err_bootstrap)\n",
    "training_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "948feb94-7897-45aa-8859-5cf587363e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy with .632 leave-one-out bootstrapping: 0.745\n"
     ]
    }
   ],
   "source": [
    "accuracy_632 = 0.632 * bootstrap_err + 0.368 * training_err\n",
    "print(f'Mean accuracy with .632 leave-one-out bootstrapping: {accuracy_632:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff442a7-9bf9-4714-b56b-f35a2caaa43e",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83684f1-1beb-433e-8d1b-6763add6864d",
   "metadata": {},
   "source": [
    "Of course, when training ML models, we want to tune their hyperparameters in order to optimize the performance. In order to tune the hyperparameters of a model, we need to do further splits of our data set. To do so, we can freely combine the approaches presented in the model assessment section. In the following, we present a few ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab3ad2-2260-4747-9353-0021799fb1d0",
   "metadata": {},
   "source": [
    "### Example 1: Train-Test-Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906b203-6451-4a2e-b36e-e284690699e1",
   "metadata": {},
   "source": [
    "In the first example we use a train-test setting to perform the outer split (model assessment) as well as the inner split (model selection). We hold out 20% of the data for testing and 10% of the data for validation (for hyperparameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e09002f-ece0-4650-a45c-6b4a2597a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the test set as 20% of the initial data set\n",
    "X_1, X_test, y_1, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f0820cd-3a3b-4ed6-80c0-5530ff822987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the training set as 70% of the initial dataset\n",
    "# Select the validation set at 10% of the initial dataset (we use 1/8 here because we've already split the set once)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_1, y_1, test_size=1/8, random_state=42, stratify=y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ef3c29d-9a52-4816-b741-aa5b7fec8f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute a grid search across the following parameter space\n",
    "parameters = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': np.arange(3, 9),\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "}\n",
    "\n",
    "params_grid = ParameterGrid(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ee91665-24ad-4df2-bd93-adf0c41672f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each combination of candidate parameters, fit a classifier on the training set and evaluate it on the validation set\n",
    "results = [[params, compute_scores(RandomForestClassifier(random_state=42, **params), \n",
    "                                   X_train, y_train, X_val, y_val)] for params in params_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddc06c98-b7a5-4e93-b55c-060f9fd5eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort candidate parameters according to their accuracy\n",
    "results = sorted(results, key=lambda x: x[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d6fb0dc-5842-47b5-87a4-3c88bcca9fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 4,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the best parameters\n",
    "best_params = results[0][0]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9886672f-c4f0-41b4-ac89-199e5710d215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train-validation-test setting: 0.681\n",
      "AUC for train-validation-test setting: 0.739\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a model based on the best parameter settings\n",
    "clf = RandomForestClassifier(random_state=42, **best_params)\n",
    "accuracy, AUC = compute_scores(clf, X_1, y_1, X_test, y_test)\n",
    "\n",
    "print(f'Accuracy for train-validation-test setting: {accuracy}')\n",
    "print(f'AUC for train-validation-test setting: {AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af1deb-e2e1-4f19-b238-8eece0b99150",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example 2: Nested 10-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda333a-5570-4d74-8f16-9d517f1ea1ed",
   "metadata": {},
   "source": [
    "We use a 10-fold cross validation to perform the outer split (model assessment) as well as the inner split (model selection), leading to a **nested** 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51ffb3e2-a727-4140-b5c3-efc63ad04a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute a grid search across the following parameter space\n",
    "parameters = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': np.arange(3, 7),\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2f46d71-1910-493b-bd79-6ad52a9e1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes ~3 minutes to run\n",
    "\n",
    "# Inner cross validation loop\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters, cv=10)\n",
    "\n",
    "# Outer cross validation loop\n",
    "scores_nested_cv = cross_validate(clf, X, y, cv=10, scoring=['accuracy', 'roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af9b5f5c-7eaa-429a-b307-fbdc398d0b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy with nested cross-validation: 0.717\n",
      "Mean AUC with nested cross-validation: 0.699\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean accuracy with nested cross-validation: {scores_nested_cv[\"test_accuracy\"].mean():.3f}')\n",
    "print(f'Mean AUC with nested cross-validation: {scores_nested_cv[\"test_roc_auc\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b2dbb-7c7b-47e2-9c1c-a2b075ee7a89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example 3: Cross Validation with Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f9d866-e055-4cdf-9ebf-ee85c47c63a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "We perform cross validation on the bootstrap data set from before to tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e50edcc4-4adc-47d9-be30-1a329ca5d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute a grid search across the following parameter space\n",
    "parameters = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'criterion': ['gini'],\n",
    "    'max_depth': np.arange(3, 7),\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2711b789-f195-42f5-b83f-4d550b522faa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_size = len(df_lq)\n",
    "B = 100\n",
    "\n",
    "# Generate B samples with replacement\n",
    "samples = [resample(X, y, replace=True, n_samples=df_size) for b in range(B)]\n",
    "# Train a random forest classifier for each sample, cross-validating to find the best parameters\n",
    "clfs = [GridSearchCV(RandomForestClassifier(random_state=42), parameters, cv=5).fit(X_b, y_b) for X_b, y_b in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc6ce94f-f28f-4bfb-9683-0ea24f4236d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predictions for each bootstrap sample (b in range(B)).\n",
    "# Compare predictions against the ground truth (y.loc[[user]]). \n",
    "# Take the mean of predictions for each student (over on the number of times they were predicted).\n",
    "# Takes ~2 mins\n",
    "accuracies_bootstrap = [np.mean([clfs[b].predict(X.loc[[user]]) == y.loc[[user]] for b in range(B) if user not in samples[b][0].index])\n",
    "                        for user in df_lq.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a716579-8793-48ec-977c-7c5a168baac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741332512299202"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the mean of predictions across all students.\n",
    "bootstrap_err = np.mean(accuracies_bootstrap)\n",
    "bootstrap_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1b8b235a-4eff-43f9-a2c4-6d205a92e839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710638297872342"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the training error for each bootstrapped model, then average across bootstraps.\n",
    "training_err_bootstrap = [clfs[b].score(samples[b][0], samples[b][1]) for b in range(B)]\n",
    "training_err = np.mean(training_err_bootstrap)\n",
    "training_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bff35009-9d3c-46a0-8f0e-efcfa34ad21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy with .632 leave-one-out bootstrapping: 0.786\n"
     ]
    }
   ],
   "source": [
    "accuracy_632 = 0.632 * bootstrap_err + 0.368 * training_err\n",
    "print(f'Mean accuracy with .632 leave-one-out bootstrapping: {accuracy_632:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c051e4-2109-47d2-9ace-0cbfaab83809",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Example 4: Train-Test (Outer Loop) + 10-Fold Cross Validation (Inner Loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d6f94-af3c-412e-a673-29f12cfb5caf",
   "metadata": {},
   "source": [
    "We perform a train-test outer split and use 10-fold cross validation on the inner split to tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "18479a4b-90c8-45ad-be4a-005deed6bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create outer loop with stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3caad318-4ec2-468b-a3cd-37e5b4af0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute a grid search across the following parameter space\n",
    "parameters = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': np.arange(3, 7),\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc2ffc35-e288-412d-849f-edeaaf242c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on inner loop with grid-search 10-fold cross validation\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters, cv=10)\n",
    "accuracy, AUC = compute_scores(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b2f4d5c-d61d-4335-84ff-1dfbb65493a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c67a4355-4226-4b8f-a0d4-8c906be03b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train-test splitting + cross-validation: 0.638\n",
      "AUC for train-test splitting + cross-validation: 0.724\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for train-test splitting + cross-validation: {accuracy:.3f}')\n",
    "print(f'AUC for train-test splitting + cross-validation: {AUC:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc2ff8-2a7b-4e77-b8fc-9520a7658e03",
   "metadata": {},
   "source": [
    "## Reporting Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e896ce5-d926-4c36-965d-bc11c03b52e4",
   "metadata": {},
   "source": [
    "When reporting results, it is good practice to report the uncertainty of the prediction. In the following, we provide examples on how to assess the uncertainty of the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e587cf9d-157f-4e60-8673-6fc4fa823bcb",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab70a0-8dc3-40c9-9418-54c0e8fb8e70",
   "metadata": {},
   "source": [
    "When performing cross validation we can compute the standard deviation (or standard error) of the performance metric across folds. We use a nested cross validated (10-fold, stratified) for the Random Forest model and tune the hyperparameters (example 2b above). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785223d0-4cda-49e5-9fa8-f1b9ac1e9ee4",
   "metadata": {},
   "source": [
    "Using the results from [Example 2](#Example-2:-Correct), we recover the accuracy and the AUC over all 10 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8647bcf1-5fc7-4662-861a-d470d8f8b27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([24.46057653, 24.21984887, 24.61662054, 24.94931316, 24.6724658 ,\n",
       "        24.6104784 , 24.91920877, 24.45852089, 24.31214809, 24.38347864]),\n",
       " 'score_time': array([0.01716542, 0.01692367, 0.02932286, 0.02874398, 0.01694226,\n",
       "        0.01028013, 0.01666737, 0.02875972, 0.01692915, 0.02793384]),\n",
       " 'test_accuracy': array([0.75      , 0.66666667, 0.66666667, 0.91666667, 0.65217391,\n",
       "        0.73913043, 0.65217391, 0.69565217, 0.82608696, 0.60869565]),\n",
       " 'test_roc_auc': array([0.77037037, 0.57857143, 0.71428571, 0.91428571, 0.53174603,\n",
       "        0.80952381, 0.5952381 , 0.69047619, 0.80952381, 0.57142857])}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_nested_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3de3206d-3eab-4dc8-986e-893ad99037fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy standard deviation with nested cross-validation: 0.089\n",
      "AUC standard deviation with nested cross-validation: 0.121\n"
     ]
    }
   ],
   "source": [
    "accuracies_nested_cv = scores_nested_cv['test_accuracy']\n",
    "AUC_nested_cv = scores_nested_cv['test_roc_auc']\n",
    "\n",
    "# Compute standard deviation of Accuracy and AUC\n",
    "print(f'Accuracy standard deviation with nested cross-validation: {accuracies_nested_cv.std():.3f}')\n",
    "print(f'AUC standard deviation with nested cross-validation: {AUC_nested_cv.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd06dcbd-6db1-407b-8b47-8462d05c6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group scores in a DataFrame for visualization with error bars\n",
    "cv_df = pd.DataFrame({'Accuracy': accuracies_nested_cv, 'AUC': AUC_nested_cv, 'Method': ['nested cv']*10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5fb9a-9110-418e-abf3-5ea1ddf50f26",
   "metadata": {},
   "source": [
    "### Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06900616-1248-454c-af64-19c11d0b903f",
   "metadata": {
    "tags": []
   },
   "source": [
    "When performing bootstrapping, we can also compute uncertainty, because we get multiple predictions for one sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c21616-0a1a-400b-8480-e30344bee081",
   "metadata": {},
   "source": [
    "Again, using the results from [Example 3](#Example-3), we recover the accuracy for each sample. To assess the uncertainty of the .632 accuracy, we need to sum them beforehand with the weighted training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a9a0023-b4b3-430e-9604-83ec81753f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine accuracy 632 across bootstrap and training error\n",
    "accuracies_632 = 0.632 * np.array(accuracies_bootstrap) + 0.368 * training_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "398a1e0f-fc3c-4b68-bc3d-8158ef12e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy standard deviation with .632 bootstrapping: 0.234\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy standard deviation with .632 bootstrapping: {accuracies_632.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6afcd13-d4c5-4101-b11b-31f97742757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC is None here (as discussed earlier in the notebook) because the ROC curve cannot be computed for leave-one-out bootstrap.\n",
    "# Group scores in a DataFrame for visualization with error bars.\n",
    "bootstrap_df = pd.DataFrame({'Accuracy': accuracies_632, 'AUC': [None] * df_size, 'Method': ['.632 bootstrap'] * df_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60821fd2-8423-4c1c-91ac-8a2056624ce3",
   "metadata": {},
   "source": [
    "### Train-Test + Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787237f6-fc11-4f57-89c5-0cc3f063e4e2",
   "metadata": {},
   "source": [
    "Instead of using a full bootstrap, we can do a train-test split first and train the model on the training data. We can then perfrom bootstrapping on the test set and generate a 100 bootstrapped test sets. This enables us to examine the uncertainty for this setting. We use a similar setting to [Example 4](#Example-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5e247c86-1b25-4706-b7a3-e676895f9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create outer loop with train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "56373ee8-9622-43bf-873a-66b23f8568a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': array([3, 4, 5, 6]),\n",
       "                         'min_samples_leaf': [1], 'min_samples_split': [2],\n",
       "                         'n_estimators': [20, 50, 100]})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a Random Forest classifier using a grid search (via cross validation) on the training data\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters, cv=10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "02334546-cc3a-4d8b-8968-a72243966166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're using the bootstrap over the test set, it's important to resample the same size (test_size), randomly, with replacement (replace=True)\n",
    "test_size = len(X_test)\n",
    "B = 100\n",
    "\n",
    "# Generate B samples with replacement\n",
    "samples = [resample(X_test, y_test, replace=True, n_samples=test_size) for b in range(B)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9b195725-4a49-417d-9bde-1d6f65145d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy and the AUC for each bootstrapped sample\n",
    "accuracies_split_bootstrap = [clf.score(X_b, y_b) for X_b, y_b in samples]\n",
    "AUC_split_bootstrap = [roc_auc_score(y_b, clf.predict_proba(X_b)[:, 1]) for X_b, y_b in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "775046c4-64dd-48eb-86a4-b590963c0a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy standard deviation with split + bootstrapping: 0.077\n",
      "AUC standard deviation with split + bootstrapping: 0.095\n"
     ]
    }
   ],
   "source": [
    "# Compute the standard deviation of the accuracies and AUC scores across bootstraps\n",
    "print(f'Accuracy standard deviation with split + bootstrapping: {np.std(accuracies_split_bootstrap):.3f}')\n",
    "print(f'AUC standard deviation with split + bootstrapping: {np.std(AUC_split_bootstrap):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd42ab4a-2854-4376-8bf1-24731453e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group scores in a DataFrame for visualization with error bars\n",
    "split_bootstrap_df = pd.DataFrame({'Accuracy': accuracies_split_bootstrap, 'AUC': AUC_split_bootstrap, 'Method': ['split_bootstrap'] * B})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a810d-6aca-4c6a-a742-71abd10e7c4b",
   "metadata": {},
   "source": [
    "### Visualizing uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6a1faf18-230d-45f2-bc3e-6a71b3dd38a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>nested cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>nested cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>nested cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>nested cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.531746</td>\n",
       "      <td>nested cv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy       AUC     Method\n",
       "0  0.750000  0.770370  nested cv\n",
       "1  0.666667  0.578571  nested cv\n",
       "2  0.666667  0.714286  nested cv\n",
       "3  0.916667  0.914286  nested cv\n",
       "4  0.652174  0.531746  nested cv"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the three experiments together for visualization\n",
    "df = pd.concat([cv_df, bootstrap_df, split_bootstrap_df])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb375c-3254-4c5c-8695-d3b2872efefd",
   "metadata": {},
   "source": [
    "Here, the error bars represent the 95% confidence intervals across our three experiments (cross validation, bootstrap, train-test split + bootrap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9fcd03fa-6078-4659-b73c-6b094f7d55f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Method', ylabel='Accuracy'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Method', y='Accuracy', data=df, ci=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c343140d-6864-4bf2-a315-f70d6a454818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Method', ylabel='AUC'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Method', y='AUC', data=df[df.Method != '.632 bootstrap'], ci=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97202b13-208b-48c5-86ea-6cfef595e98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
